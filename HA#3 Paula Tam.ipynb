{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ff04d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word: matches\n",
      "matches does not match with any of the words within the corpus Penn Treebank (WSJ #88).\n",
      "Here are the top 5 closest matches (based on their edit distances) and their probabilities (rounded to two decimal points) within the corpus are:\n",
      "the , probability: 72 / 778 or 9.25 %\n",
      "at , probability: 7 / 778 or 0.9 %\n",
      "he , probability: 8 / 778 or 1.03 %\n",
      "as , probability: 2 / 778 or 0.26 %\n",
      "late , probability: 1 / 778 or 0.13 %\n"
     ]
    }
   ],
   "source": [
    "#CSC620\n",
    "#HA#3\n",
    "#Paula Abigail Tam <921850992>\n",
    "\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.corpus import treebank #so I can fulfill the word frequency requirement\n",
    "from collections import Counter #to count stuff\n",
    "import operator #for operator.itemgetter(1) \n",
    "\n",
    "def normalize_words(corpus_tokens):\n",
    "    new_tokens = [word for word in corpus_tokens if word.isalpha()] #only accepts alphabetical words\n",
    "    return new_tokens\n",
    "\n",
    "def corpus_counter(tokens): #if Counter is not allowed, make a dictionary like in HA#2\n",
    "    corpus_word_count = Counter(tokens)\n",
    "    return corpus_word_count\n",
    "    \n",
    "def corpus_words():\n",
    "    #print(treebank.fileids())\n",
    "    new_words = treebank.words('wsj_0088.mrg') #picked a random corpus\n",
    "    new_words = [word.lower() for word in new_words] #iterator through the words to make them all lowercase\n",
    "    just_words = normalize_words(new_words)\n",
    "    #print(len(just_words)) #1030 words total, not normalized, 778 with normalization (removing non-alpha words)\n",
    "    return just_words #returns the whole corpus as a normalized list\n",
    "\n",
    "#combines both corpus counter and words functions together so I don't have to write it out all the time\n",
    "def words_in_corpus():\n",
    "    return corpus_counter(corpus_words()) #returns a dictionary of words and the number of times they appear\n",
    "\n",
    "def word_frequency(user_input):\n",
    "    if user_input in words_in_corpus():\n",
    "        total_words = len(corpus_words()) #should be 778\n",
    "        num_times = words_in_corpus().get(user_input) #using .get() instead of [] so I don't throw an error\n",
    "        rel_freq = (num_times / total_words) * 100 #relative frequency of the word in the corpus\n",
    "        #print(total_words, \",\", num_times) #double checking\n",
    "        return round(rel_freq, 2)\n",
    "    \n",
    "def find_lev_distance(user_input):\n",
    "    top_five_dict = {}\n",
    "    for word in words_in_corpus():\n",
    "        distance = edit_distance(user_input, word, 2) #made the substitution cost to 2\n",
    "        top_five_dict[word] = distance #populate dictionary with words + edit distance\n",
    "    #sorted by edit distance, ascending so the first 5 are the lowest ones\n",
    "    sorted_dict = dict(sorted(top_five_dict.items(), key=operator.itemgetter(1))[:5])\n",
    "    return sorted_dict\n",
    "    \n",
    "def take_user_input():\n",
    "    user_input = input(\"Enter a word: \")\n",
    "    if user_input in corpus_words():\n",
    "        is_match(user_input)\n",
    "    else:\n",
    "        isnt_match(user_input)\n",
    "    \n",
    "def is_match(user_input):\n",
    "    print(user_input, \"is a complete and correct word as per corpus Penn Treebank (WSJ #88), and its probability is about\",\n",
    "          words_in_corpus().get(user_input), \"/\", len(corpus_words()), \"or\", word_frequency(user_input), \"%.\") #shows the relative frequency of the word in the corpus \n",
    "    \n",
    "def isnt_match(user_input):\n",
    "    top_matches = find_lev_distance(user_input)\n",
    "    print(user_input, \"does not match with any of the words within the corpus Penn Treebank (WSJ #88).\")\n",
    "    print(\"Here are the top 5 closest matches (based on their edit distances) and their probabilities (rounded to two decimal points) within the corpus are:\")\n",
    "    for word in top_matches: #in ascending order of edit distance\n",
    "        print(word, \", probability:\", words_in_corpus().get(word), \"/\", len(corpus_words()), \"or\", word_frequency(word), \"%\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    take_user_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d2c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e605a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c808a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eccc9ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSC620\n",
    "#HA9 -- sklearn's Pipeline and FeatureUnion\n",
    "#Paula Abigail Tam\n",
    "#a. Uses Logistic Regression instead of Random Forest classifier.\n",
    "#b. Adds three new features: Number of adjectives, Number of nouns, Number of verbs. \n",
    "#c. At the end of the blocks 9 and 13, add the function 'classification_report()' to print the detailed evaluation report (prec, recall, f1 etc.).\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "df = pd.read_csv('./HA9_csv/train.csv') #My path to the train.csv file is this\n",
    "#('../input/train.csv') \n",
    "\n",
    "df.dropna(axis=0) #.dropna removes any missing values, so there is no empty values in the data\n",
    "    #documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "df.set_index('id', inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b1b317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>224</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>202</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id26305  this process however afforded me no means of a...     224     41   \n",
       "id17569  it never once occurred to me that the fumbling...      70     14   \n",
       "id11008  in his left hand was a gold snuff box from whi...     195     36   \n",
       "id27763  how lovely is spring as we looked from windsor...     202     34   \n",
       "id12958  finding nothing else not even gold the superin...     170     27   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \n",
       "id                                                    \n",
       "id26305                  21         6.380952       4  \n",
       "id17569                   6         6.166667       0  \n",
       "id11008                  19         5.947368       4  \n",
       "id27763                  21         6.476190       3  \n",
       "id12958                  16         7.187500       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english')) #makes a set of the stopwords \n",
    "\n",
    "#creating a function to encapsulate preprocessing, to make it easy to replicate on  submission data\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' '))) #total words\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords])) #words that arent stopwords\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    df['commas'] = df['text'].apply(lambda x: x.count(',')) #count the number of commas in the text\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "df = processing(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5162b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id19417</th>\n",
       "      <td>this panorama is indeed glorious and i should ...</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09522</th>\n",
       "      <td>there was a simple natural earnestness about h...</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>6.277778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22732</th>\n",
       "      <td>who are you pray that i duc de lomelette princ...</td>\n",
       "      <td>387</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>5.552632</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10351</th>\n",
       "      <td>he had gone in the carriage to the nearest tow...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24580</th>\n",
       "      <td>there is no method in their proceedings beyond...</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id19417  this panorama is indeed glorious and i should ...      91     18   \n",
       "id09522  there was a simple natural earnestness about h...     240     44   \n",
       "id22732  who are you pray that i duc de lomelette princ...     387     74   \n",
       "id10351  he had gone in the carriage to the nearest tow...     118     24   \n",
       "id24580  there is no method in their proceedings beyond...      71     13   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \n",
       "id                                                    \n",
       "id19417                   6         6.666667       1  \n",
       "id09522                  18         6.277778       4  \n",
       "id22732                  38         5.552632       9  \n",
       "id10351                  11         5.363636       0  \n",
       "id24580                   5         7.000000       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features= [c for c in df.columns.values if c not in ['id','text','author']] #if it is not in the text, author, id columns\n",
    "numeric_features= [c for c in df.columns.values if c not in ['id','text','author','processed']] #all the numeric features\n",
    "target = 'author'\n",
    "#splitting the train set using just the processed and author columns, iterates the whole processed column each time?\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.33, random_state=42) #test will be 1/3 and train will be 2/3\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6775f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#BaseEstimator documentation: https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html\n",
    "#this is the base for all estimators\n",
    "\n",
    "#TransformerMixin documentation: https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html\n",
    "#a mixin is a class that provides methods for other classes\n",
    "#so the TransformerMixin specifically is a mixin class for all transformers\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "#these class definitions is so we are able to pipeline the columns in our dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bcde8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 148061 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline #documentation: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "#pipelines sequentially apply a list transform + give a final estimator\n",
    "#in this case the transforms are either TextSelector or NumberSelector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#start creating the first pipeline with the processed text\n",
    "#since text is... well text, we use the TextSelector for our transformation\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            ])\n",
    "\n",
    "text.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0c9e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50769254],\n",
       "       [ 0.88000324],\n",
       "       [ 2.24907223],\n",
       "       ...,\n",
       "       [-0.46112557],\n",
       "       [-0.14447015],\n",
       "       [-0.39593181]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler #documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "#standardizing the feature(s) -> removes mean and scaling to unit variance\n",
    "#weird behavior might happen if the feature data doesnt look like a standard normal distribution \n",
    "\n",
    "#length is numeric, so use the NumberSelector transformer\n",
    "length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "length.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b1f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more pipelines to make the features\n",
    "\n",
    "words =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "words_not_stopword =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words_not_stopword')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "avg_word_length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='avg_word_length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "commas =  Pipeline([\n",
    "                ('selector', NumberSelector(key='commas')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2fa051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21521 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 213646 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion #documentation: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html\n",
    "#FeatureUnion concatenates transformers together\n",
    "#in this case it can concatenate all of our features\n",
    "\n",
    "#make all our features all in one variable ==> creates one transformer\n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('words_not_stopword', words_not_stopword),\n",
    "                      ('avg_word_length', avg_word_length),\n",
    "                      ('commas', commas)])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)]) #using pipeline on feats transformer\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7c5b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7808727948003714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP       0.74      0.85      0.79      2587\n",
      "         HPL       0.81      0.74      0.77      1852\n",
      "         MWS       0.83      0.73      0.78      2023\n",
      "\n",
      "    accuracy                           0.78      6462\n",
      "   macro avg       0.79      0.77      0.78      6462\n",
      "weighted avg       0.79      0.78      0.78      6462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression #replacing the RandomForestClassifier with Logistic Regression\n",
    "from sklearn.metrics import classification_report #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "\n",
    "#using the feats transformer + classifier in the new pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42, max_iter=500)), # replaced RandomForestClassifier(random_state = 42)) with the LogisticRegression version\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "preds = pipeline.predict(X_test)\n",
    "print(np.mean(preds == y_test)) #the prediction\n",
    "print(classification_report(y_test, preds)) #the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8a7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping the CV part\n",
    "\n",
    "#imports to get the part-of-speech tags and tokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#add the pos tags to the words in each text in each row\n",
    "def add_pos_tags(df):\n",
    "    df['pos'] = df['processed'].apply(lambda x: nltk.pos_tag(word_tokenize(x)))\n",
    "    return df\n",
    "\n",
    "df = add_pos_tags(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a09c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the 3 features: noun, adj, verb\n",
    "def process_pos(df, pos): \n",
    "    full_list = []\n",
    "    for row in df['pos']:\n",
    "        #new_list = [] #initially had a list of tuples\n",
    "        count = 0\n",
    "        for key, val in row:\n",
    "            if val == pos: #if the value matches with the given string (e.g. 'JJ', NN', 'VB')\n",
    "                #new_list.append((key, val)) #put tuple with the word (key) and pos (val)\n",
    "                count += 1 #increment count\n",
    "        full_list.append(count) #put whole list of that row\n",
    "    return full_list #returns list of lengths of the number of whatever pos was specified\n",
    "\n",
    "#checking if the lengths are all the same\n",
    "#print(len(df))\n",
    "#print(len(process_pos(df, 'NN')))\n",
    "#print(len(process_pos(df, 'JJ')))\n",
    "#print(len(process_pos(df, 'VB')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a40fe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>pos</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>224</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>4</td>\n",
       "      <td>[(this, DT), (process, NN), (however, RB), (af...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>[(it, PRP), (never, RB), (once, RB), (occurred...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>4</td>\n",
       "      <td>[(in, IN), (his, PRP$), (left, JJ), (hand, NN)...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>202</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>3</td>\n",
       "      <td>[(how, WRB), (lovely, RB), (is, VBZ), (spring,...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>2</td>\n",
       "      <td>[(finding, VBG), (nothing, NN), (else, RB), (n...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id26305  this process however afforded me no means of a...     224     41   \n",
       "id17569  it never once occurred to me that the fumbling...      70     14   \n",
       "id11008  in his left hand was a gold snuff box from whi...     195     36   \n",
       "id27763  how lovely is spring as we looked from windsor...     202     34   \n",
       "id12958  finding nothing else not even gold the superin...     170     27   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \\\n",
       "id                                                     \n",
       "id26305                  21         6.380952       4   \n",
       "id17569                   6         6.166667       0   \n",
       "id11008                  19         5.947368       4   \n",
       "id27763                  21         6.476190       3   \n",
       "id12958                  16         7.187500       2   \n",
       "\n",
       "                                                       pos  adjectives  nouns  \\\n",
       "id                                                                              \n",
       "id26305  [(this, DT), (process, NN), (however, RB), (af...           2     10   \n",
       "id17569  [(it, PRP), (never, RB), (once, RB), (occurred...           1      2   \n",
       "id11008  [(in, IN), (his, PRP$), (left, JJ), (hand, NN)...           4      9   \n",
       "id27763  [(how, WRB), (lovely, RB), (is, VBZ), (spring,...           5      6   \n",
       "id12958  [(finding, VBG), (nothing, NN), (else, RB), (n...           1      5   \n",
       "\n",
       "         verbs  \n",
       "id              \n",
       "id26305      1  \n",
       "id17569      1  \n",
       "id11008      0  \n",
       "id27763      0  \n",
       "id12958      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_adj = process_pos(df, 'JJ') #JJ is adjective\n",
    "pos_n = process_pos(df, 'NN') #NN is noun\n",
    "pos_v = process_pos(df, 'VB') #VB is verb\n",
    "\n",
    "#making the new columns for our new features\n",
    "df['adjectives'] = pos_adj\n",
    "df['nouns'] = pos_n\n",
    "df['verbs'] = pos_v\n",
    "\n",
    "df.head() #to check our new dataframe w/ adj, noun, and verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac960d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id19417</th>\n",
       "      <td>this panorama is indeed glorious and i should ...</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09522</th>\n",
       "      <td>there was a simple natural earnestness about h...</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>6.277778</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22732</th>\n",
       "      <td>who are you pray that i duc de lomelette princ...</td>\n",
       "      <td>387</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>5.552632</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10351</th>\n",
       "      <td>he had gone in the carriage to the nearest tow...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24580</th>\n",
       "      <td>there is no method in their proceedings beyond...</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id19417  this panorama is indeed glorious and i should ...      91     18   \n",
       "id09522  there was a simple natural earnestness about h...     240     44   \n",
       "id22732  who are you pray that i duc de lomelette princ...     387     74   \n",
       "id10351  he had gone in the carriage to the nearest tow...     118     24   \n",
       "id24580  there is no method in their proceedings beyond...      71     13   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  adjectives  nouns  verbs  \n",
       "id                                                                              \n",
       "id19417                   6         6.666667       1           1      4      1  \n",
       "id09522                  18         6.277778       4           6      6      0  \n",
       "id22732                  38         5.552632       9           1     15      4  \n",
       "id10351                  11         5.363636       0           0      6      0  \n",
       "id24580                   5         7.000000       1           0      3      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copying the previous code to make the test and train sets, but it now includes the adj, noun, and verb columns and excludes the pos column\n",
    "features= [c for c in df.columns.values if c not in ['id','text','author', 'pos']] #everything else other than the stuff we dont care about (not data)\n",
    "numeric_features= [c for c in df.columns.values if c not in ['id','text','author','processed', 'pos']] #the features with numeric values\n",
    "target = 'author'\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.33, random_state=42) #test will be 1/3 and train will be 2/3\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c755e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 148061 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text = Pipeline([\n",
    "                #('selector', TextSelector(key='processed')),\n",
    "                #('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            #])\n",
    "\n",
    "#copied this line since X_train is different this time\n",
    "text.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d51c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making new pipelines for the pos following the previous examples\n",
    "#used NumberSelector since the values of these columns are all numeric\n",
    "adjectives =  Pipeline([\n",
    "                ('selector', NumberSelector(key='adjectives')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "nouns =  Pipeline([\n",
    "                ('selector', NumberSelector(key='nouns')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "verbs =  Pipeline([\n",
    "                ('selector', NumberSelector(key='verbs')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ec446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21524 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 252997 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also basically copy pasted the previous stuff, just added the new features\n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('words_not_stopword', words_not_stopword),\n",
    "                      ('avg_word_length', avg_word_length),\n",
    "                      ('commas', commas),\n",
    "                      ('adjectives', adjectives),\n",
    "                      ('nouns', nouns),\n",
    "                      ('verbs', verbs)])\n",
    "\n",
    "#using the premade feature + the new pos features\n",
    "#process the new features\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cefdadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7862890745899103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP       0.74      0.85      0.79      2587\n",
      "         HPL       0.81      0.74      0.78      1852\n",
      "         MWS       0.84      0.74      0.79      2023\n",
      "\n",
      "    accuracy                           0.79      6462\n",
      "   macro avg       0.80      0.78      0.79      6462\n",
      "weighted avg       0.79      0.79      0.79      6462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#basically copy pasted the same thing as before\n",
    "#except named each variable with the suffix _pos to differentiate between the previous one\n",
    "pipeline_pos = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42, max_iter=500)),\n",
    "])\n",
    "\n",
    "pipeline_pos.fit(X_train, y_train)\n",
    "\n",
    "preds_pos = pipeline_pos.predict(X_test)\n",
    "print(np.mean(preds_pos == y_test))\n",
    "print(classification_report(y_test, preds_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab02440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After adding the 3 new features ('adjectives', 'nouns', and 'verbs'), the precision did increase, but only by about .006.\n",
    "#I think it increased because of the addition of new features slightly helped the accuracy.\n",
    "#more features = more accurate\n",
    "#Though the increase is small. I think this is because the pos_tags I used for the adjectives, nouns, and verbs were just the basic ones (JJ, NN, VB).\n",
    "#If I had added the more tags (e.g. if I added the tags JJR (adjective, comparative) and JJS (adjective, superlative)) to the adjective column, the count would probably increase.\n",
    "#page I looked at for the pos tag abbreviations: https://www.guru99.com/pos-tagging-chunking-nltk.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
